{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime; start = datetime.now()\n",
    "import gc\n",
    "from logging import getLogger, FileHandler, StreamHandler, Formatter, DEBUG, INFO\n",
    "import os\n",
    "import random, re\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "debug = False\n",
    "# model\n",
    "emb_size = 300\n",
    "max_features = 120000\n",
    "maxlen = 70\n",
    "embedding_trainable = False\n",
    "# data\n",
    "test_size = 0.1\n",
    "random_state = 2018\n",
    "batch_size = 512\n",
    "batch_size_val = 4096\n",
    "# training\n",
    "n_splits = 5\n",
    "lr = 0.001\n",
    "epochs = 5\n",
    "early_stopping = False\n",
    "min_delta = 0.\n",
    "patience = 5\n",
    "thresholds = np.arange(0.3, 0.501, 0.01)\n",
    "device = 'cuda:0'\n",
    "\n",
    "seed = 2018\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "emb_paths = {\n",
    "    'glove': '../input/embeddings/glove.840B.300d/glove.840B.300d.txt',\n",
    "    'fasttext': '../input/embeddings/wiki-news-300d-1M/wiki-news-300d-1M.vec',\n",
    "    'paragram': '../input/embeddings/paragram_300_sl999/paragram_300_sl999.txt',\n",
    "    # 'google': '../input/embeddings/GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin'    \n",
    "}\n",
    "# https://www.kaggle.com/theoviel/improve-your-score-with-text-preprocessing-v2\n",
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\" }\n",
    "punctuation = \"/-'?!.,#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~\" + '\"\"“”’' + '∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—–&'\n",
    "punctuation_mapping = {\"‘\": \"'\", \"₹\": \"e\", \"´\": \"'\", \"°\": \"\", \"€\": \"e\", \"™\": \"tm\", \"√\": \" sqrt \", \"×\": \"x\", \"²\": \"2\", \"—\": \"-\", \"–\": \"-\", \"’\": \"'\", \"_\": \"-\", \"`\": \"'\", '“': '\"', '”': '\"', '“': '\"', \"£\": \"e\", '∞': 'infinity', 'θ': 'theta', '÷': '/', 'α': 'alpha', '•': '.', 'à': 'a', '−': '-', 'β': 'beta', '∅': '', '³': '3', 'π': 'pi', }\n",
    "misspell_dict = {'colour': 'color', 'centre': 'center', 'favourite': 'favorite', 'travelling': 'traveling', 'counselling': 'counseling', 'theatre': 'theater', 'cancelled': 'canceled', 'labour': 'labor', 'organisation': 'organization', 'wwii': 'world war 2', 'citicise': 'criticize', 'youtu ': 'youtube ', 'Qoura': 'Quora', 'sallary': 'salary', 'Whta': 'What', 'narcisist': 'narcissist', 'howdo': 'how do', 'whatare': 'what are', 'howcan': 'how can', 'howmuch': 'how much', 'howmany': 'how many', 'whydo': 'why do', 'doI': 'do I', 'theBest': 'the best', 'howdoes': 'how does', 'mastrubation': 'masturbation', 'mastrubate': 'masturbate', \"mastrubating\": 'masturbating', 'pennis': 'penis', 'Etherium': 'Ethereum', 'narcissit': 'narcissist', 'bigdata': 'big data', '2k17': '2017', '2k18': '2018', 'qouta': 'quota', 'exboyfriend': 'ex boyfriend', 'airhostess': 'air hostess', \"whst\": 'what', 'watsapp': 'whatsapp', 'demonitisation': 'demonetization', 'demonitization': 'demonetization', 'demonetisation': 'demonetization', 'pokémon': 'pokemon'}\n",
    "\n",
    "# logger\n",
    "fh = FileHandler('log.txt')\n",
    "fh.setLevel(DEBUG)\n",
    "sh = StreamHandler()\n",
    "sh.setLevel(INFO)\n",
    "for handler in [fh, sh]:\n",
    "    formatter = Formatter('%(asctime)s - %(message)s')\n",
    "    handler.setFormatter(formatter)\n",
    "logger = getLogger(__name__)\n",
    "logger.setLevel(INFO)\n",
    "logger.addHandler(fh)\n",
    "logger.addHandler(sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coefs(word, *arr):\n",
    "    return word, np.asarray(arr, dtype='float32')   \n",
    "\n",
    "    \n",
    "def get_embedding(path, word_index, name='glove'):\n",
    "    if name.lower() == 'glove':\n",
    "        embeddings_index = dict(get_coefs(*o.split(' '))[:300] for o in open(path))\n",
    "    elif name.lower() == 'fasttext':\n",
    "        embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(path) if len(o) > 100)\n",
    "    elif name.lower() == 'paragram':\n",
    "        embeddings_index = dict(\n",
    "            get_coefs(*o.split(\" \"))\n",
    "            for o in open(path, encoding=\"utf8\", errors='ignore') if len(o) > 100)\n",
    "    elif name.lower() == 'google':\n",
    "        loaded = KeyedVectors.load_word2vec_format(path, binary=True)\n",
    "        embeddings_index = dict([(k, loaded[k]) for k in loaded.vocab.keys()])\n",
    "    else:\n",
    "        raise NotImplementedError('No embedding: {}'.format(name))\n",
    "    logger.info('Created embedding_index.')\n",
    "\n",
    "    all_embs = np.stack(embeddings_index.values())\n",
    "    emb_mean, emb_std = all_embs.mean(), all_embs.std()\n",
    "    emb_size = all_embs.shape[1]\n",
    "    n_words = min(max_features, len(word_index))\n",
    "    logger.info('Creating embedding_matrix')\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (n_words, emb_size))\n",
    "    for word, i in tqdm(word_index.items()):\n",
    "        if i >= max_features:\n",
    "            continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    #     else:\n",
    "    #         embedding_vector = embeddings_index.get(word.capitalize())\n",
    "    #         if embedding_vector is not None:\n",
    "    #             embedding_matrix[i] = embedding_vector\n",
    "    del embeddings_index, all_embs, embedding_vector\n",
    "    gc.collect()\n",
    "    return embedding_matrix\n",
    "\n",
    "\n",
    "def preprocess_contraction(text, mapping):\n",
    "    '''\n",
    "    https://www.kaggle.com/theoviel/improve-your-score-with-text-preprocessing-v2\n",
    "    '''\n",
    "    specials = [\"’\", \"‘\", \"´\", \"`\"]\n",
    "    for s in specials:\n",
    "        text = text.replace(s, \"'\")\n",
    "    text = ' '.join([mapping[t] if t in mapping else t for t in text.split(\" \")])\n",
    "    return text\n",
    "\n",
    "\n",
    "def preprocess_punctuation(text, punctuation, mapping):\n",
    "    '''\n",
    "    https://www.kaggle.com/theoviel/improve-your-score-with-text-preprocessing-v2\n",
    "    '''\n",
    "    specials = {'\\u200b': ' ', '…': ' ... ', '\\ufeff': '', 'करना': '', 'है': ''}\n",
    "    for p in mapping:\n",
    "        text = text.replace(p, mapping[p])\n",
    "    for p in punctuation:\n",
    "        text = text.replace(p, f' {p} ')\n",
    "    for s in specials:\n",
    "        text = text.replace(s, specials[s])\n",
    "    \n",
    "    return text\n",
    "    \n",
    "    \n",
    "def clean_punctuation(x):\n",
    "    puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', \n",
    " '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n",
    " '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n",
    " '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n",
    " '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\n",
    "    x = str(x)\n",
    "    for punct in puncts:\n",
    "        x = x.replace(punct, f' {punct} ')\n",
    "    return x\n",
    "\n",
    "\n",
    "def clean_number(x):\n",
    "    x = re.sub('[0-9]{5,}', '#####', x)\n",
    "    x = re.sub('[0-9]{4}', '####', x)\n",
    "    x = re.sub('[0-9]{3}', '###', x)\n",
    "    x = re.sub('[0-9]{2}', '##', x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def preprocess_misspell(text, dictinary):\n",
    "    '''\n",
    "    https://www.kaggle.com/theoviel/improve-your-score-with-text-preprocessing-v2\n",
    "    '''\n",
    "    for word in dictionary.keys():\n",
    "        text = text.replace(word, dictinary[word])\n",
    "    return text\n",
    "\n",
    "\n",
    "def _get_mispell(mispell_dict):\n",
    "    mispell_re = re.compile('(%s)' % '|'.join(mispell_dict.keys()))\n",
    "    return mispell_dict, mispell_re\n",
    "\n",
    "\n",
    "def replace_typical_misspell(text):\n",
    "    mispell_dict = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\", 'colour': 'color', 'centre': 'center', 'favourite': 'favorite', 'travelling': 'traveling', 'counselling': 'counseling', 'theatre': 'theater', 'cancelled': 'canceled', 'labour': 'labor', 'organisation': 'organization', 'wwii': 'world war 2', 'citicise': 'criticize', 'youtu ': 'youtube ', 'Qoura': 'Quora', 'sallary': 'salary', 'Whta': 'What', 'narcisist': 'narcissist', 'howdo': 'how do', 'whatare': 'what are', 'howcan': 'how can', 'howmuch': 'how much', 'howmany': 'how many', 'whydo': 'why do', 'doI': 'do I', 'theBest': 'the best', 'howdoes': 'how does', 'mastrubation': 'masturbation', 'mastrubate': 'masturbate', \"mastrubating\": 'masturbating', 'pennis': 'penis', 'Etherium': 'Ethereum', 'narcissit': 'narcissist', 'bigdata': 'big data', '2k17': '2017', '2k18': '2018', 'qouta': 'quota', 'exboyfriend': 'ex boyfriend', 'airhostess': 'air hostess', \"whst\": 'what', 'watsapp': 'whatsapp', 'demonitisation': 'demonetization', 'demonitization': 'demonetization', 'demonetisation': 'demonetization'}\n",
    "    mispellings, mispellings_re = _get_mispell(mispell_dict)\n",
    "    def replace(match):\n",
    "        return mispellings[match.group(0)]\n",
    "    return mispellings_re.sub(replace, text)\n",
    "\n",
    "\n",
    "def preprocess(df):\n",
    "    df['question_text'] = df['question_text'].apply(lambda x: x.lower())\n",
    "    df['question_text'] = df['question_text'].apply(lambda text: clean_punctuation(text))\n",
    "    df['question_text'] = df['question_text'].apply(lambda text: clean_number(text))\n",
    "    df['question_text'] = df['question_text'].apply(lambda text: replace_typical_misspell(text))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size, step_size, bias=True, **kwargs):\n",
    "        super(Attention, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.step_size = step_size\n",
    "        \n",
    "        weight = torch.zeros(hidden_size, 1)\n",
    "        nn.init.xavier_uniform_(weight)\n",
    "        self.weight = nn.Parameter(weight)\n",
    "        self.bias = nn.Parameter(torch.zeros(step_size)) if bias else None\n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        eij = torch.mm(x.contiguous().view(-1, self.hidden_size), self.weight).view(-1, self.step_size)\n",
    "        if self.bias is not None:\n",
    "            eij += self.bias\n",
    "        eij = torch.tanh(eij)\n",
    "        a = torch.exp(eij)\n",
    "        if mask is not None:\n",
    "            a = a * mask\n",
    "        a = a / torch.sum(a, dim=1, keepdim=True) + 1e-10\n",
    "        weighted = x * torch.unsqueeze(a, -1)\n",
    "        return torch.sum(weighted, dim=1)\n",
    "\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self, vocab_size, embedding_dim=300, embedding=None, embedding_trainable=False,\n",
    "        hidden_dim=64, n_layers=1, device='cuda:0'\n",
    "    ):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.device = device\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        if embedding is not None:\n",
    "            self.embedding.weight = nn.Parameter(torch.tensor(embedding, dtype=torch.float32))\n",
    "            self.embedding.weight.requires_grad = embedding_trainable\n",
    "        # TODO: SpatialDropout1D\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.lstm = nn.LSTM(\n",
    "            embedding_dim, hidden_dim, num_layers=n_layers, bias=False, batch_first=True, dropout=0.,\n",
    "            bidirectional=True)\n",
    "        self.gru = nn.GRU(\n",
    "            hidden_dim * 2, hidden_dim, num_layers=n_layers, bias=False, batch_first=True, dropout=0.,\n",
    "            bidirectional=True)\n",
    "        self.attn_gru = Attention(hidden_dim * 2, maxlen)\n",
    "        self.fc1 = nn.Linear(hidden_dim * 2, 16)\n",
    "        self.bn = nn.BatchNorm1d(16)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(16, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        bs = x.size(0)\n",
    "        h0 = torch.zeros(self.n_layers * 2, bs, self.hidden_dim).to(self.device)\n",
    "        c0 = torch.zeros(self.n_layers * 2, bs, self.hidden_dim).to(self.device)\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        x = self.dropout1(x)\n",
    "        x, (h, c) = self.lstm(x, (h0, c0))\n",
    "        x, hidden = self.gru(x, h)\n",
    "        x = self.attn_gru(x)\n",
    "        x = x.view(bs, -1)\n",
    "        x = self.relu(self.bn(self.fc1(x)))\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(model, inputs, targets, criterion, device):\n",
    "    inputs, targets = inputs.to(device), targets.to(device)\n",
    "    out = model(inputs)\n",
    "    loss = criterion(out, targets)\n",
    "    return out, loss\n",
    "\n",
    "\n",
    "def train(model, data_loader, criterion, optimizer, device):\n",
    "    losses = AverageMeter()\n",
    "    model.train()\n",
    "    for inputs, targets in data_loader:\n",
    "        bs = inputs.size(0)\n",
    "        out, loss = step(model, inputs, targets, criterion, device)\n",
    "        losses.update(loss.item(), bs)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "        optimizer.step()\n",
    "    return losses.avg\n",
    "\n",
    "\n",
    "def validate(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    losses = AverageMeter()\n",
    "    outputs, trues = [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in data_loader:\n",
    "            bs = inputs.size(0)\n",
    "            out, loss = step(model, inputs, targets, criterion, device)\n",
    "            losses.update(loss.item(), bs)\n",
    "            outputs += out.detach().cpu().numpy().tolist()\n",
    "            trues += targets.detach().numpy().tolist()\n",
    "    f1, thresh = f1_score_for_thresholds(trues, outputs)\n",
    "    return {'loss': losses.avg, 'f1': f1, 'thresh': thresh, 'output': np.array(outputs).flatten()}\n",
    "\n",
    "\n",
    "def test(model, data_loader, device):\n",
    "    model.eval()\n",
    "    outputs = []\n",
    "    with torch.no_grad():\n",
    "        for (inputs,) in data_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            out = model(inputs)\n",
    "            outputs += out.detach().cpu().numpy().tolist()\n",
    "    return np.array(outputs).flatten()\n",
    "\n",
    "\n",
    "\n",
    "class EarlyStopping(object):\n",
    "    '''\n",
    "    cf. https://gist.github.com/stefanonardo/693d96ceb2f531fa05db530f3e21517d\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, mode='min', min_delta=0, patience=10, percentage=False):\n",
    "        self.mode = mode\n",
    "        self.min_delta = min_delta\n",
    "        self.patience = patience\n",
    "        self.best = None\n",
    "        self.num_bad_epochs = 0\n",
    "        self.is_better = None\n",
    "        self._init_is_better(mode, min_delta, percentage)\n",
    "\n",
    "        if patience == 0:\n",
    "            self.is_better = lambda a, b: True\n",
    "            self.step = lambda a: False\n",
    "\n",
    "    def step(self, metrics):\n",
    "        if self.best is None:\n",
    "            self.best = metrics\n",
    "            return False\n",
    "\n",
    "        if np.isnan(metrics):\n",
    "            return True\n",
    "\n",
    "        if self.is_better(metrics, self.best):\n",
    "            self.num_bad_epochs = 0\n",
    "            self.best = metrics\n",
    "        else:\n",
    "            self.num_bad_epochs += 1\n",
    "\n",
    "        if self.num_bad_epochs >= self.patience:\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def _init_is_better(self, mode, min_delta, percentage):\n",
    "        if mode not in {'min', 'max'}:\n",
    "            raise ValueError('mode ' + mode + ' is unknown!')\n",
    "        if not percentage:\n",
    "            if mode == 'min':\n",
    "                self.is_better = lambda a, best: a < best - min_delta\n",
    "            if mode == 'max':\n",
    "                self.is_better = lambda a, best: a > best + min_delta\n",
    "        else:\n",
    "            if mode == 'min':\n",
    "                self.is_better = lambda a, best: a < best - (\n",
    "                            best * min_delta / 100)\n",
    "            if mode == 'max':\n",
    "                self.is_better = lambda a, best: a > best + (\n",
    "                            best * min_delta / 100)\n",
    "    \n",
    "    \n",
    "class AverageMeter(object):\n",
    "    \"\"\"\n",
    "    Computes and stores the average and current value\n",
    "    cf. https://github.com/pytorch/examples/blob/master/imagenet/main.py#L296\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "        \n",
    "def f1_score_for_thresholds(y_true, proba):\n",
    "    precision, recall, thresholds = metrics.precision_recall_curve(y_true, proba)\n",
    "    thresholds = np.append(thresholds, 1.001)\n",
    "    F1 = 2 / (1 / precision + 1 / recall)\n",
    "    best_f1 = np.max(F1)\n",
    "    best_threshold = thresholds[np.argmax(F1)]\n",
    "    return best_f1, best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "debug = False\n",
    "# model\n",
    "emb_size = 300\n",
    "max_features = 120000\n",
    "maxlen = 70\n",
    "embedding_trainable = False\n",
    "# data\n",
    "test_size = 0.1\n",
    "random_state = 2018\n",
    "batch_size = 512\n",
    "batch_size_val = 4096\n",
    "# training\n",
    "n_splits = 5\n",
    "lr = 0.001\n",
    "epochs = 5\n",
    "early_stopping = False\n",
    "min_delta = 0.\n",
    "patience = 5\n",
    "thresholds = np.arange(0.3, 0.501, 0.01)\n",
    "device = 'cpu'  # 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-30 11:28:54,748 - Preprocessed in 65.70338487625122\n",
      "2019-01-30 11:28:54,748 - Preprocessed in 65.70338487625122\n",
      "2019-01-30 11:28:54,748 - Preprocessed in 65.70338487625122\n",
      "2019-01-30 11:29:26,017 - Tokenized in 31.268032789230347\n",
      "2019-01-30 11:29:26,017 - Tokenized in 31.268032789230347\n",
      "2019-01-30 11:29:26,017 - Tokenized in 31.268032789230347\n",
      "2019-01-30 11:29:29,564 - Padding in 3.5456230640411377\n",
      "2019-01-30 11:29:29,564 - Padding in 3.5456230640411377\n",
      "2019-01-30 11:29:29,564 - Padding in 3.5456230640411377\n",
      "2019-01-30 11:31:02,931 - Created embedding_index.\n",
      "2019-01-30 11:31:02,931 - Created embedding_index.\n",
      "2019-01-30 11:31:02,931 - Created embedding_index.\n",
      "2019-01-30 11:31:06,453 - Creating embedding_matrix\n",
      "2019-01-30 11:31:06,453 - Creating embedding_matrix\n",
      "2019-01-30 11:31:06,453 - Creating embedding_matrix\n",
      "100%|██████████| 185777/185777 [00:00<00:00, 1104649.24it/s]\n",
      "2019-01-30 11:31:48,631 - Created embedding_index.\n",
      "2019-01-30 11:31:48,631 - Created embedding_index.\n",
      "2019-01-30 11:31:48,631 - Created embedding_index.\n",
      "2019-01-30 11:31:50,420 - Creating embedding_matrix\n",
      "2019-01-30 11:31:50,420 - Creating embedding_matrix\n",
      "2019-01-30 11:31:50,420 - Creating embedding_matrix\n",
      "100%|██████████| 185777/185777 [00:00<00:00, 1317952.61it/s]\n",
      "2019-01-30 11:33:04,771 - Created embedding_index.\n",
      "2019-01-30 11:33:04,771 - Created embedding_index.\n",
      "2019-01-30 11:33:04,771 - Created embedding_index.\n",
      "2019-01-30 11:33:07,497 - Creating embedding_matrix\n",
      "2019-01-30 11:33:07,497 - Creating embedding_matrix\n",
      "2019-01-30 11:33:07,497 - Creating embedding_matrix\n",
      "100%|██████████| 185777/185777 [00:00<00:00, 1140776.66it/s]\n"
     ]
    }
   ],
   "source": [
    "# data\n",
    "df_train = pd.read_csv('../input/train.csv')\n",
    "df_test = pd.read_csv('../input/test.csv')\n",
    "# preprocess\n",
    "t0 = time()\n",
    "df_train = preprocess(df_train)\n",
    "df_test = preprocess(df_test)\n",
    "X_train = df_train['question_text'].fillna('_na_').values\n",
    "X_test = df_test['question_text'].fillna('_na_').values\n",
    "logger.info('Preprocessed in {}'.format(time() - t0))\n",
    "# tokenize\n",
    "t0 = time()\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(X_train))\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "logger.info('Tokenized in {}'.format(time() - t0))\n",
    "# padding\n",
    "t0 = time()\n",
    "X_train = pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, maxlen=maxlen)\n",
    "logger.info('Padding in {}'.format(time() - t0))\n",
    "# target\n",
    "y_train = df_train['target'].values\n",
    "# shuffle\n",
    "indices = np.random.permutation(len(X_train))\n",
    "X_train, y_train = X_train[indices], y_train[indices]\n",
    "# embedding\n",
    "if debug:\n",
    "    embedding = None\n",
    "else:\n",
    "    embeddings = []\n",
    "    for name, path in emb_paths.items():\n",
    "        embeddings.append(get_embedding(path, tokenizer.word_index, name=name))\n",
    "    embedding = np.mean(embeddings, axis=0)\n",
    "    del embeddings\n",
    "    gc.collect()\n",
    "# data loader\n",
    "test_dataset = TensorDataset(torch.from_numpy(X_test.astype('int64')))\n",
    "test_loader = DataLoader(test_dataset, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../input/X_train.npy', X_train)\n",
    "np.save('../input/y_train.npy', y_train)\n",
    "np.save('../input/X_test.npy', X_test)\n",
    "np.save('../input/mean_embedding.npy', embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('../input/X_train.npy')\n",
    "y_train = np.load('../input/y_train.npy')\n",
    "X_test = np.load('../input/X_test.npy')\n",
    "embedding = np.load('../input/mean_embedding.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-a634bf38a60b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mvalidation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         logger.info('Fold {} Epoch {} Train/Loss {:.4f} Val/Loss {:.4f} Val/F1 {:.4f} (Threshold = {:.2f})'.format(\n",
      "\u001b[0;32m<ipython-input-6-014f9770a86a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, data_loader, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;31m# nn.utils.clip_grad_norm_(net.parameters(), clip)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deep/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deep/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "proba_train, proba_test = np.zeros(len(df_train)), np.zeros(len(df_test))\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "for fold_i, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train)):\n",
    "    fold_i += 1\n",
    "    # split\n",
    "    X_train_fold, y_train_fold = X_train[train_idx].astype('int64'), y_train[train_idx].astype('float32')\n",
    "    X_val_fold, y_val_fold = X_train[val_idx].astype('int64'), y_train[val_idx].astype('float32')\n",
    "    train_dataset = TensorDataset(torch.from_numpy(X_train_fold), torch.from_numpy(y_train_fold))\n",
    "    val_dataset = TensorDataset(torch.from_numpy(X_val_fold), torch.from_numpy(y_val_fold))\n",
    "    train_loader  = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size, shuffle=False)\n",
    "\n",
    "    # model\n",
    "    model = RNN(\n",
    "        max_features, embedding_dim=emb_size, embedding=embedding, embedding_trainable=embedding_trainable,\n",
    "        device=device).to(device)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    if early_stopping:\n",
    "        early_stop = EarlyStopping(mode='min', min_delta=min_delta, patience=patience, percentage=False)\n",
    "\n",
    "    for epoch_i in range(1, 1 + epochs):\n",
    "        loss = train(model, train_loader, criterion, optimizer, device)\n",
    "        validation = validate(model, val_loader, criterion, device)\n",
    "        logger.info('Fold {} Epoch {} Train/Loss {:.4f} Val/Loss {:.4f} Val/F1 {:.4f} (Threshold = {:.2f})'.format(\n",
    "            fold_i, epoch_i, loss, validation['loss'], validation['f1'], validation['thresh']))\n",
    "        if early_stopping:\n",
    "            if early_stop.step(validation['loss']):\n",
    "                logger.info('Fold {} Early stop'.format(fold_i))\n",
    "                break\n",
    "        if debug: break\n",
    "    proba_train[val_idx] = validation['output']\n",
    "    logger.info('Fold {} Finished training'.format(fold_i))\n",
    "\n",
    "    proba = test(model, test_loader, device)\n",
    "    proba_test += proba / n_splits\n",
    "    logger.info('Fold {} Scored test probabilities'.format(fold_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit\n",
    "f1, threshold = f1_score_for_thresholds(y_train, proba_train)\n",
    "logger.info('Train/F1/Best {:.4f} (Threshold = {:.2f})'.format(f1, threshold))\n",
    "\n",
    "y_pred = (proba_test > threshold).astype('int')\n",
    "submit = pd.read_csv('../input/sample_submission.csv')\n",
    "submit.prediction = y_pred\n",
    "submit.to_csv('submission.csv', index=False)\n",
    "\n",
    "elapsed = datetime.now() - start\n",
    "logger.info('{}h {}m {}s'.format(*str(elapsed).split(':')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "deep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
